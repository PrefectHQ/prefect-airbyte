{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"prefect-airbyte Welcome! prefect-airbyte is a collections of prebuilt Prefect tasks that can be used to quickly construct Prefect flows. Getting Started Python setup Requires an installation of Python 3.7+ We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation . Installation Install prefect-airbyte pip install prefect-airbyte Airbyte setup See the airbyte documention on how to get your own instance. Examples Trigger a defined connection sync from prefect import flow from prefect_airbyte.connections import trigger_sync @flow def example_trigger_sync_flow (): # Run other tasks and subflows here trigger_sync ( connection_id = \"your-connection-id-to-sync\" , poll_interval_s = 3 , status_updates = True ) example_trigger_sync_flow () \u276f python airbyte_syncs.py 03:46:03 | prefect.engine - Created flow run 'thick-seahorse' for flow 'example_trigger_sync_flow' 03:46:03 | Flow run 'thick-seahorse' - Using task runner 'ConcurrentTaskRunner' 03:46:03 | Flow run 'thick-seahorse' - Created task run 'trigger_sync-35f0e9c2-0' for task 'trigger_sync' 03:46:03 | prefect - trigger airbyte connection: e1b2078f-882a-4f50-9942-cfe34b2d825b, poll interval 3 seconds 03:46:03 | prefect - pending 03:46:06 | prefect - running 03:46:09 | prefect - running 03:46:12 | prefect - running 03:46:16 | prefect - running 03:46:19 | prefect - running 03:46:22 | prefect - Job 26 succeeded. 03:46:22 | Task run 'trigger_sync-35f0e9c2-0' - Finished in state Completed(None) 03:46:22 | Flow run 'thick-seahorse' - Finished in state Completed('All states completed.') Export an Airbyte instance's configuration import gzip from prefect import flow , task from prefect_airbyte.configuration import export_configuration @task def zip_and_write_somewhere ( airbyte_config : bytearray somewhere : str = '*://**/my_destination.gz' , ): with gzip . open ( somewhere , 'wb' ) as f : f . write ( airbyte_configuration ) @flow def example_export_configuration_flow (): # Run other tasks and subflows here airbyte_config = export_configuration ( airbyte_server_host = \"localhost\" , airbyte_server_port = \"8000\" , airbyte_api_version = \"v1\" , ) zip_and_write_somewhere ( airbyte_config = airbyte_config ) example_trigger_sync_flow () Resources If you encounter and bugs while using prefect-airbyte , feel free to open an issue in the prefect-airbyte repository. If you have any questions or issues while using prefect-airbyte , you can find help in either the Prefect Discourse forum or the Prefect Slack community Development If you'd like to install a version of prefect-airbyte for development, first clone the repository and then perform an editable install with pip : git clone https://github.com/PrefectHQ/prefect-airbyte.git cd prefect-airbyte/ pip install -e \".[dev]\"","title":"Home"},{"location":"#prefect-airbyte","text":"","title":"prefect-airbyte"},{"location":"#welcome","text":"prefect-airbyte is a collections of prebuilt Prefect tasks that can be used to quickly construct Prefect flows.","title":"Welcome!"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#python-setup","text":"Requires an installation of Python 3.7+ We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation .","title":"Python setup"},{"location":"#installation","text":"Install prefect-airbyte pip install prefect-airbyte","title":"Installation"},{"location":"#airbyte-setup","text":"See the airbyte documention on how to get your own instance.","title":"Airbyte setup"},{"location":"#examples","text":"","title":"Examples"},{"location":"#trigger-a-defined-connection-sync","text":"from prefect import flow from prefect_airbyte.connections import trigger_sync @flow def example_trigger_sync_flow (): # Run other tasks and subflows here trigger_sync ( connection_id = \"your-connection-id-to-sync\" , poll_interval_s = 3 , status_updates = True ) example_trigger_sync_flow () \u276f python airbyte_syncs.py 03:46:03 | prefect.engine - Created flow run 'thick-seahorse' for flow 'example_trigger_sync_flow' 03:46:03 | Flow run 'thick-seahorse' - Using task runner 'ConcurrentTaskRunner' 03:46:03 | Flow run 'thick-seahorse' - Created task run 'trigger_sync-35f0e9c2-0' for task 'trigger_sync' 03:46:03 | prefect - trigger airbyte connection: e1b2078f-882a-4f50-9942-cfe34b2d825b, poll interval 3 seconds 03:46:03 | prefect - pending 03:46:06 | prefect - running 03:46:09 | prefect - running 03:46:12 | prefect - running 03:46:16 | prefect - running 03:46:19 | prefect - running 03:46:22 | prefect - Job 26 succeeded. 03:46:22 | Task run 'trigger_sync-35f0e9c2-0' - Finished in state Completed(None) 03:46:22 | Flow run 'thick-seahorse' - Finished in state Completed('All states completed.')","title":"Trigger a defined connection sync"},{"location":"#export-an-airbyte-instances-configuration","text":"import gzip from prefect import flow , task from prefect_airbyte.configuration import export_configuration @task def zip_and_write_somewhere ( airbyte_config : bytearray somewhere : str = '*://**/my_destination.gz' , ): with gzip . open ( somewhere , 'wb' ) as f : f . write ( airbyte_configuration ) @flow def example_export_configuration_flow (): # Run other tasks and subflows here airbyte_config = export_configuration ( airbyte_server_host = \"localhost\" , airbyte_server_port = \"8000\" , airbyte_api_version = \"v1\" , ) zip_and_write_somewhere ( airbyte_config = airbyte_config ) example_trigger_sync_flow ()","title":"Export an Airbyte instance's configuration"},{"location":"#resources","text":"If you encounter and bugs while using prefect-airbyte , feel free to open an issue in the prefect-airbyte repository. If you have any questions or issues while using prefect-airbyte , you can find help in either the Prefect Discourse forum or the Prefect Slack community","title":"Resources"},{"location":"#development","text":"If you'd like to install a version of prefect-airbyte for development, first clone the repository and then perform an editable install with pip : git clone https://github.com/PrefectHQ/prefect-airbyte.git cd prefect-airbyte/ pip install -e \".[dev]\"","title":"Development"},{"location":"client/","text":"prefect_airbyte.client Client for interacting with Airbyte instance AirbyteClient Esablishes a session with an Airbyte instance and evaluates its current health status. This client assumes that you're using Airbyte Open-Source, since \"For Airbyte Open-Source you don't need the API Token for Authentication! All endpoints are possible to access using the API without it.\" For more information refer to the Airbyte docs . Parameters: Name Type Description Default airbyte_base_url str base api endpoint url for airbyte 'http://localhost:8000/api/v1' Returns: Type Description AirbyteClient an instance of AirbyteClient Source code in prefect_airbyte/client.py class AirbyteClient : \"\"\" Esablishes a session with an Airbyte instance and evaluates its current health status. This client assumes that you're using Airbyte Open-Source, since \"For Airbyte Open-Source you don't need the API Token for Authentication! All endpoints are possible to access using the API without it.\" For more information refer to the [Airbyte docs](https://docs.airbyte.io/api-documentation). Args: airbyte_base_url str: base api endpoint url for airbyte Returns: AirbyteClient: an instance of AirbyteClient \"\"\" def __init__ ( self , logger , airbyte_base_url : str = \"http://localhost:8000/api/v1\" ): self . airbyte_base_url = airbyte_base_url self . logger = logger def establish_session ( self ): session = requests . Session () if self . check_health_status ( session ): return session def check_health_status ( self , session ): get_connection_url = self . airbyte_base_url + \"/health/\" try : response = session . get ( get_connection_url ) self . logger . debug ( \"Health check response: %s \" , response . json ()) key = \"available\" if \"available\" in response . json () else \"db\" health_status = response . json ()[ key ] if not health_status : raise err . AirbyteServerNotHealthyException ( f \"Airbyte Server health status: { health_status } \" ) return True except RequestException as e : raise err . AirbyteServerNotHealthyException ( e ) def export_configuration ( self , airbyte_base_url : str , session : requests . Session , ) -> bytearray : \"\"\" Trigger an export of Airbyte configuration &mdash; [see the airbyte docs for `/v1/deployment/export`](https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html#post-/v1/deployment/export). Args: airbyte_base_url: URL of Airbyte server. session: requests session with which to make call to the Airbyte server logger: task logger Returns: - byte array of Airbyte configuration data \"\"\" get_connection_url = airbyte_base_url + \"/deployment/export/\" try : response = session . post ( get_connection_url ) if response . status_code == 200 : self . logger . debug ( \"Export configuration response: %s \" , response ) export_config = response . content return export_config except RequestException as e : raise err . AirbyteExportConfigurationFailed ( e ) def get_connection_status ( self , session , airbyte_base_url , connection_id ): get_connection_url = airbyte_base_url + \"/connections/get/\" # TODO - Missing authentication because Airbyte servers currently do not support authentication try : response = session . post ( get_connection_url , json = { \"connectionId\" : connection_id } ) response . raise_for_status () connection_status = response . json ()[ \"status\" ] return connection_status except RequestException as e : raise err . AirbyteServerNotHealthyException ( e ) def trigger_manual_sync_connection ( self , session , airbyte_base_url , connection_id ): \"\"\" Trigger a manual sync of the Connection &mdash; [see the airbyte docs for /v1/connections/sync](https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html#post-/v1/connections/sync). Args: session: requests session with which to make call to Airbyte server airbyte_base_url: URL of Airbyte server connection_id: ID of connection to sync Returns: created_at - timestamp of sync job creation \"\"\" get_connection_url = airbyte_base_url + \"/connections/sync/\" # TODO - missing authentication ... try : response = session . post ( get_connection_url , json = { \"connectionId\" : connection_id } ) if response . status_code == 200 : job_id = response . json ()[ \"job\" ][ \"id\" ] job_created_at = response . json ()[ \"job\" ][ \"createdAt\" ] return job_id , job_created_at elif response . status_code == 404 : # connection_id not found self . logger . warning ( f \"Connection { connection_id } not found, please double \" f \"check the connection_id ...\" ) raise err . ConnectionNotFoundException ( f \"Connection { connection_id } not found, please double \" f \"check the connection_id ...\" ) except RequestException as e : raise err . AirbyteServerNotHealthyException ( e ) def get_job_status ( self , session , airbyte_base_url , job_id ): get_connection_url = airbyte_base_url + \"/jobs/get/\" try : response = session . post ( get_connection_url , json = { \"id\" : job_id }) if response . status_code == 200 : job_status = response . json ()[ \"job\" ][ \"status\" ] job_created_at = response . json ()[ \"job\" ][ \"createdAt\" ] job_updated_at = response . json ()[ \"job\" ][ \"updatedAt\" ] return job_status , job_created_at , job_updated_at elif response . status_code == 404 : self . logger . error ( f \"Job { job_id } not found...\" ) raise err . JobNotFoundException ( f \"Job { job_id } not found...\" ) except RequestException as e : raise err . AirbyteServerNotHealthyException ( e ) export_configuration ( self , airbyte_base_url , session ) Trigger an export of Airbyte configuration \u2014 see the airbyte docs for /v1/deployment/export . Parameters: Name Type Description Default airbyte_base_url str URL of Airbyte server. required session Session requests session with which to make call to the Airbyte server required logger task logger required Returns: Type Description bytearray byte array of Airbyte configuration data Source code in prefect_airbyte/client.py def export_configuration ( self , airbyte_base_url : str , session : requests . Session , ) -> bytearray : \"\"\" Trigger an export of Airbyte configuration &mdash; [see the airbyte docs for `/v1/deployment/export`](https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html#post-/v1/deployment/export). Args: airbyte_base_url: URL of Airbyte server. session: requests session with which to make call to the Airbyte server logger: task logger Returns: - byte array of Airbyte configuration data \"\"\" get_connection_url = airbyte_base_url + \"/deployment/export/\" try : response = session . post ( get_connection_url ) if response . status_code == 200 : self . logger . debug ( \"Export configuration response: %s \" , response ) export_config = response . content return export_config except RequestException as e : raise err . AirbyteExportConfigurationFailed ( e ) trigger_manual_sync_connection ( self , session , airbyte_base_url , connection_id ) Trigger a manual sync of the Connection \u2014 see the airbyte docs for /v1/connections/sync . Parameters: Name Type Description Default session requests session with which to make call to Airbyte server required airbyte_base_url URL of Airbyte server required connection_id ID of connection to sync required Source code in prefect_airbyte/client.py def trigger_manual_sync_connection ( self , session , airbyte_base_url , connection_id ): \"\"\" Trigger a manual sync of the Connection &mdash; [see the airbyte docs for /v1/connections/sync](https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html#post-/v1/connections/sync). Args: session: requests session with which to make call to Airbyte server airbyte_base_url: URL of Airbyte server connection_id: ID of connection to sync Returns: created_at - timestamp of sync job creation \"\"\" get_connection_url = airbyte_base_url + \"/connections/sync/\" # TODO - missing authentication ... try : response = session . post ( get_connection_url , json = { \"connectionId\" : connection_id } ) if response . status_code == 200 : job_id = response . json ()[ \"job\" ][ \"id\" ] job_created_at = response . json ()[ \"job\" ][ \"createdAt\" ] return job_id , job_created_at elif response . status_code == 404 : # connection_id not found self . logger . warning ( f \"Connection { connection_id } not found, please double \" f \"check the connection_id ...\" ) raise err . ConnectionNotFoundException ( f \"Connection { connection_id } not found, please double \" f \"check the connection_id ...\" ) except RequestException as e : raise err . AirbyteServerNotHealthyException ( e )","title":"Client"},{"location":"client/#prefect_airbyte.client","text":"Client for interacting with Airbyte instance","title":"client"},{"location":"client/#prefect_airbyte.client.AirbyteClient","text":"Esablishes a session with an Airbyte instance and evaluates its current health status. This client assumes that you're using Airbyte Open-Source, since \"For Airbyte Open-Source you don't need the API Token for Authentication! All endpoints are possible to access using the API without it.\" For more information refer to the Airbyte docs . Parameters: Name Type Description Default airbyte_base_url str base api endpoint url for airbyte 'http://localhost:8000/api/v1' Returns: Type Description AirbyteClient an instance of AirbyteClient Source code in prefect_airbyte/client.py class AirbyteClient : \"\"\" Esablishes a session with an Airbyte instance and evaluates its current health status. This client assumes that you're using Airbyte Open-Source, since \"For Airbyte Open-Source you don't need the API Token for Authentication! All endpoints are possible to access using the API without it.\" For more information refer to the [Airbyte docs](https://docs.airbyte.io/api-documentation). Args: airbyte_base_url str: base api endpoint url for airbyte Returns: AirbyteClient: an instance of AirbyteClient \"\"\" def __init__ ( self , logger , airbyte_base_url : str = \"http://localhost:8000/api/v1\" ): self . airbyte_base_url = airbyte_base_url self . logger = logger def establish_session ( self ): session = requests . Session () if self . check_health_status ( session ): return session def check_health_status ( self , session ): get_connection_url = self . airbyte_base_url + \"/health/\" try : response = session . get ( get_connection_url ) self . logger . debug ( \"Health check response: %s \" , response . json ()) key = \"available\" if \"available\" in response . json () else \"db\" health_status = response . json ()[ key ] if not health_status : raise err . AirbyteServerNotHealthyException ( f \"Airbyte Server health status: { health_status } \" ) return True except RequestException as e : raise err . AirbyteServerNotHealthyException ( e ) def export_configuration ( self , airbyte_base_url : str , session : requests . Session , ) -> bytearray : \"\"\" Trigger an export of Airbyte configuration &mdash; [see the airbyte docs for `/v1/deployment/export`](https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html#post-/v1/deployment/export). Args: airbyte_base_url: URL of Airbyte server. session: requests session with which to make call to the Airbyte server logger: task logger Returns: - byte array of Airbyte configuration data \"\"\" get_connection_url = airbyte_base_url + \"/deployment/export/\" try : response = session . post ( get_connection_url ) if response . status_code == 200 : self . logger . debug ( \"Export configuration response: %s \" , response ) export_config = response . content return export_config except RequestException as e : raise err . AirbyteExportConfigurationFailed ( e ) def get_connection_status ( self , session , airbyte_base_url , connection_id ): get_connection_url = airbyte_base_url + \"/connections/get/\" # TODO - Missing authentication because Airbyte servers currently do not support authentication try : response = session . post ( get_connection_url , json = { \"connectionId\" : connection_id } ) response . raise_for_status () connection_status = response . json ()[ \"status\" ] return connection_status except RequestException as e : raise err . AirbyteServerNotHealthyException ( e ) def trigger_manual_sync_connection ( self , session , airbyte_base_url , connection_id ): \"\"\" Trigger a manual sync of the Connection &mdash; [see the airbyte docs for /v1/connections/sync](https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html#post-/v1/connections/sync). Args: session: requests session with which to make call to Airbyte server airbyte_base_url: URL of Airbyte server connection_id: ID of connection to sync Returns: created_at - timestamp of sync job creation \"\"\" get_connection_url = airbyte_base_url + \"/connections/sync/\" # TODO - missing authentication ... try : response = session . post ( get_connection_url , json = { \"connectionId\" : connection_id } ) if response . status_code == 200 : job_id = response . json ()[ \"job\" ][ \"id\" ] job_created_at = response . json ()[ \"job\" ][ \"createdAt\" ] return job_id , job_created_at elif response . status_code == 404 : # connection_id not found self . logger . warning ( f \"Connection { connection_id } not found, please double \" f \"check the connection_id ...\" ) raise err . ConnectionNotFoundException ( f \"Connection { connection_id } not found, please double \" f \"check the connection_id ...\" ) except RequestException as e : raise err . AirbyteServerNotHealthyException ( e ) def get_job_status ( self , session , airbyte_base_url , job_id ): get_connection_url = airbyte_base_url + \"/jobs/get/\" try : response = session . post ( get_connection_url , json = { \"id\" : job_id }) if response . status_code == 200 : job_status = response . json ()[ \"job\" ][ \"status\" ] job_created_at = response . json ()[ \"job\" ][ \"createdAt\" ] job_updated_at = response . json ()[ \"job\" ][ \"updatedAt\" ] return job_status , job_created_at , job_updated_at elif response . status_code == 404 : self . logger . error ( f \"Job { job_id } not found...\" ) raise err . JobNotFoundException ( f \"Job { job_id } not found...\" ) except RequestException as e : raise err . AirbyteServerNotHealthyException ( e )","title":"AirbyteClient"},{"location":"client/#prefect_airbyte.client.AirbyteClient.export_configuration","text":"Trigger an export of Airbyte configuration \u2014 see the airbyte docs for /v1/deployment/export . Parameters: Name Type Description Default airbyte_base_url str URL of Airbyte server. required session Session requests session with which to make call to the Airbyte server required logger task logger required Returns: Type Description bytearray byte array of Airbyte configuration data Source code in prefect_airbyte/client.py def export_configuration ( self , airbyte_base_url : str , session : requests . Session , ) -> bytearray : \"\"\" Trigger an export of Airbyte configuration &mdash; [see the airbyte docs for `/v1/deployment/export`](https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html#post-/v1/deployment/export). Args: airbyte_base_url: URL of Airbyte server. session: requests session with which to make call to the Airbyte server logger: task logger Returns: - byte array of Airbyte configuration data \"\"\" get_connection_url = airbyte_base_url + \"/deployment/export/\" try : response = session . post ( get_connection_url ) if response . status_code == 200 : self . logger . debug ( \"Export configuration response: %s \" , response ) export_config = response . content return export_config except RequestException as e : raise err . AirbyteExportConfigurationFailed ( e )","title":"export_configuration()"},{"location":"client/#prefect_airbyte.client.AirbyteClient.trigger_manual_sync_connection","text":"Trigger a manual sync of the Connection \u2014 see the airbyte docs for /v1/connections/sync . Parameters: Name Type Description Default session requests session with which to make call to Airbyte server required airbyte_base_url URL of Airbyte server required connection_id ID of connection to sync required Source code in prefect_airbyte/client.py def trigger_manual_sync_connection ( self , session , airbyte_base_url , connection_id ): \"\"\" Trigger a manual sync of the Connection &mdash; [see the airbyte docs for /v1/connections/sync](https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html#post-/v1/connections/sync). Args: session: requests session with which to make call to Airbyte server airbyte_base_url: URL of Airbyte server connection_id: ID of connection to sync Returns: created_at - timestamp of sync job creation \"\"\" get_connection_url = airbyte_base_url + \"/connections/sync/\" # TODO - missing authentication ... try : response = session . post ( get_connection_url , json = { \"connectionId\" : connection_id } ) if response . status_code == 200 : job_id = response . json ()[ \"job\" ][ \"id\" ] job_created_at = response . json ()[ \"job\" ][ \"createdAt\" ] return job_id , job_created_at elif response . status_code == 404 : # connection_id not found self . logger . warning ( f \"Connection { connection_id } not found, please double \" f \"check the connection_id ...\" ) raise err . ConnectionNotFoundException ( f \"Connection { connection_id } not found, please double \" f \"check the connection_id ...\" ) except RequestException as e : raise err . AirbyteServerNotHealthyException ( e )","title":"trigger_manual_sync_connection()"},{"location":"configuration/","text":"prefect_airbyte.configuration Tasks for updating and fetching Airbyte configurations export_configuration ( airbyte_server_host = 'localhost' , airbyte_server_port = '8000' , airbyte_api_version = 'v1' ) async Task that triggers an export of an Airbyte configuration per {AIRBYTE_HOST}/api/v1/deployment/export Parameters: Name Type Description Default airbyte_server_host str Hostname of Airbyte server where connection is configured. Will overwrite the value provided at init if provided. 'localhost' airbyte_server_port str Port that the Airbyte server is listening on. Will overwrite the value provided at init if provided. '8000' airbyte_api_version str Version of Airbyte API to use to trigger connection sync. Will overwrite the value provided at init if provided. 'v1' Returns: Type Description bytearray byte array containing Airbyte configuration Examples: Flow that writes the Airbyte configuration as a gzip to a filepath: import gzip from prefect import flow , task from prefect_airbyte.configuration import export_configuration @task def zip_and_write_somewhere ( airbyte_config : bytearray somwhere : str = 'my_destination.gz' , ' ): with gzip . open ( 'my_destination.gz' , 'wb' ) as f : f . write ( airbyte_configuration ) @flow def example_export_configuration_flow (): # Run other tasks and subflows here airbyte_config = export_configuration ( airbyte_server_host = \"localhost\" , airbyte_server_port = \"8000\" , airbyte_api_version = \"v1\" , ) zip_and_write_somewhere ( airbyte_config = airbyte_config ) example_trigger_sync_flow () Source code in prefect_airbyte/configuration.py @task async def export_configuration ( airbyte_server_host : str = \"localhost\" , airbyte_server_port : int = \"8000\" , airbyte_api_version : str = \"v1\" , ) -> bytearray : \"\"\" Task that triggers an export of an Airbyte configuration per `{AIRBYTE_HOST}/api/v1/deployment/export` Args: airbyte_server_host (str, optional): Hostname of Airbyte server where connection is configured. Will overwrite the value provided at init if provided. airbyte_server_port (str, optional): Port that the Airbyte server is listening on. Will overwrite the value provided at init if provided. airbyte_api_version (str, optional): Version of Airbyte API to use to trigger connection sync. Will overwrite the value provided at init if provided. Returns: bytearray: byte array containing Airbyte configuration Examples: Flow that writes the Airbyte configuration as a gzip to a filepath: ```python import gzip from prefect import flow, task from prefect_airbyte.configuration import export_configuration @task def zip_and_write_somewhere( airbyte_config: bytearray somwhere: str = 'my_destination.gz',' ): with gzip.open('my_destination.gz', 'wb') as f: f.write(airbyte_configuration) @flow def example_export_configuration_flow(): # Run other tasks and subflows here airbyte_config = export_configuration( airbyte_server_host=\"localhost\", airbyte_server_port=\"8000\", airbyte_api_version=\"v1\", ) zip_and_write_somewhere(airbyte_config=airbyte_config) example_trigger_sync_flow() ``` \"\"\" logger = get_logger () airbyte_base_url = ( f \"http:// { airbyte_server_host } :\" f \" { airbyte_server_port } /api/ { airbyte_api_version } \" ) airbyte = AirbyteClient ( logger , airbyte_base_url ) session = airbyte . establish_session () logger . info ( \"Initiating export of Airbyte configuration\" ) airbyte_config = airbyte . export_configuration ( session ) return airbyte_config","title":"Configuration"},{"location":"configuration/#prefect_airbyte.configuration","text":"Tasks for updating and fetching Airbyte configurations","title":"configuration"},{"location":"configuration/#prefect_airbyte.configuration.export_configuration","text":"Task that triggers an export of an Airbyte configuration per {AIRBYTE_HOST}/api/v1/deployment/export Parameters: Name Type Description Default airbyte_server_host str Hostname of Airbyte server where connection is configured. Will overwrite the value provided at init if provided. 'localhost' airbyte_server_port str Port that the Airbyte server is listening on. Will overwrite the value provided at init if provided. '8000' airbyte_api_version str Version of Airbyte API to use to trigger connection sync. Will overwrite the value provided at init if provided. 'v1' Returns: Type Description bytearray byte array containing Airbyte configuration Examples: Flow that writes the Airbyte configuration as a gzip to a filepath: import gzip from prefect import flow , task from prefect_airbyte.configuration import export_configuration @task def zip_and_write_somewhere ( airbyte_config : bytearray somwhere : str = 'my_destination.gz' , ' ): with gzip . open ( 'my_destination.gz' , 'wb' ) as f : f . write ( airbyte_configuration ) @flow def example_export_configuration_flow (): # Run other tasks and subflows here airbyte_config = export_configuration ( airbyte_server_host = \"localhost\" , airbyte_server_port = \"8000\" , airbyte_api_version = \"v1\" , ) zip_and_write_somewhere ( airbyte_config = airbyte_config ) example_trigger_sync_flow () Source code in prefect_airbyte/configuration.py @task async def export_configuration ( airbyte_server_host : str = \"localhost\" , airbyte_server_port : int = \"8000\" , airbyte_api_version : str = \"v1\" , ) -> bytearray : \"\"\" Task that triggers an export of an Airbyte configuration per `{AIRBYTE_HOST}/api/v1/deployment/export` Args: airbyte_server_host (str, optional): Hostname of Airbyte server where connection is configured. Will overwrite the value provided at init if provided. airbyte_server_port (str, optional): Port that the Airbyte server is listening on. Will overwrite the value provided at init if provided. airbyte_api_version (str, optional): Version of Airbyte API to use to trigger connection sync. Will overwrite the value provided at init if provided. Returns: bytearray: byte array containing Airbyte configuration Examples: Flow that writes the Airbyte configuration as a gzip to a filepath: ```python import gzip from prefect import flow, task from prefect_airbyte.configuration import export_configuration @task def zip_and_write_somewhere( airbyte_config: bytearray somwhere: str = 'my_destination.gz',' ): with gzip.open('my_destination.gz', 'wb') as f: f.write(airbyte_configuration) @flow def example_export_configuration_flow(): # Run other tasks and subflows here airbyte_config = export_configuration( airbyte_server_host=\"localhost\", airbyte_server_port=\"8000\", airbyte_api_version=\"v1\", ) zip_and_write_somewhere(airbyte_config=airbyte_config) example_trigger_sync_flow() ``` \"\"\" logger = get_logger () airbyte_base_url = ( f \"http:// { airbyte_server_host } :\" f \" { airbyte_server_port } /api/ { airbyte_api_version } \" ) airbyte = AirbyteClient ( logger , airbyte_base_url ) session = airbyte . establish_session () logger . info ( \"Initiating export of Airbyte configuration\" ) airbyte_config = airbyte . export_configuration ( session ) return airbyte_config","title":"export_configuration()"},{"location":"connections/","text":"prefect_airbyte.connections Tasks for connecting to Airbyte and triggering connection syncs trigger_sync ( airbyte_server_host = 'localhost' , airbyte_server_port = '8000' , airbyte_api_version = 'v1' , connection_id = None , poll_interval_s = 15 , status_updates = False ) async Task run method for triggering an Airbyte Connection. It is assumed that the user will have previously configured a Source & Destination into a Connection. e.g. MySql -> CSV An invocation of run will attempt to start a sync job for the specified connection_id representing the Connection in Airbyte. run will poll Airbyte Server for the Connection status and will only complete when the sync has completed or when it receives an error status code from an API call. Parameters: Name Type Description Default str airbyte_server_host Hostname of Airbyte server where connection is configured. Will overwrite the value provided at init if provided. required str airbyte_server_port Port that the Airbyte server is listening on. Will overwrite the value provided at init if provided. required str airbyte_api_version Version of Airbyte API to use to trigger connection sync. Will overwrite the value provided at init if provided. required str connection_id if provided, will overwrite the value provided at init. required int poll_interval_s this task polls the Airbyte API for status, if provided this value will override the default polling time of 15 seconds. required bool status_updates whether to log status as the task polls jobs required Returns: Type Description dict connection_id (str) and succeeded_at (timestamp str) Examples: Flow that triggers an Airybte connection sync: from prefect import flow from prefect_airbyte.connections import trigger_sync @flow def example_trigger_sync_flow (): # Run other tasks and subflows here trigger_sync ( connection_id = \"your-connection-id-to-sync\" ) example_trigger_sync_flow () Source code in prefect_airbyte/connections.py @task async def trigger_sync ( airbyte_server_host : str = \"localhost\" , airbyte_server_port : int = \"8000\" , airbyte_api_version : str = \"v1\" , connection_id : str = None , poll_interval_s : int = 15 , status_updates : bool = False ) -> dict : \"\"\" Task run method for triggering an Airbyte Connection. *It is assumed that the user will have previously configured a Source & Destination into a Connection.* e.g. MySql -> CSV An invocation of `run` will attempt to start a sync job for the specified `connection_id` representing the Connection in Airbyte. `run` will poll Airbyte Server for the Connection status and will only complete when the sync has completed or when it receives an error status code from an API call. Args: str airbyte_server_host : Hostname of Airbyte server where connection is configured. Will overwrite the value provided at init if provided. str airbyte_server_port: Port that the Airbyte server is listening on. Will overwrite the value provided at init if provided. str airbyte_api_version: Version of Airbyte API to use to trigger connection sync. Will overwrite the value provided at init if provided. str connection_id: if provided, will overwrite the value provided at init. int poll_interval_s: this task polls the Airbyte API for status, if provided this value will override the default polling time of 15 seconds. bool status_updates: whether to log status as the task polls jobs Returns: dict: connection_id (str) and succeeded_at (timestamp str) Examples: Flow that triggers an Airybte connection sync: ```python from prefect import flow from prefect_airbyte.connections import trigger_sync @flow def example_trigger_sync_flow(): # Run other tasks and subflows here trigger_sync( connection_id=\"your-connection-id-to-sync\" ) example_trigger_sync_flow() ``` \"\"\" logger = get_logger () if not connection_id : raise ValueError ( \"Value for parameter `connection_id` *must* \\ be provided.\" ) try : uuid . UUID ( connection_id ) except ( TypeError , ValueError ): raise ValueError ( \"Parameter `connection_id` *must* be a valid UUID \\ i.e. 32 hex characters, including hyphens.\" ) # see https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com # /rapidoc-api-docs.html#overview airbyte_base_url = ( f \"http:// { airbyte_server_host } :\" f \" { airbyte_server_port } /api/ { airbyte_api_version } \" ) airbyte = AirbyteClient ( logger , airbyte_base_url ) session = airbyte . establish_session () logger . info ( f \"Getting Airbyte Connection { connection_id } , poll interval \" f \" { poll_interval_s } seconds, airbyte_base_url { airbyte_base_url } \" ) connection_status = airbyte . get_connection_status ( session , airbyte_base_url , connection_id ) if connection_status == CONNECTION_STATUS_ACTIVE : # Trigger manual sync on the Connection ... job_id , job_created_at = airbyte . trigger_manual_sync_connection ( session , airbyte_base_url , connection_id ) job_status = JOB_STATUS_PENDING while job_status not in [ JOB_STATUS_FAILED , JOB_STATUS_SUCCEEDED ]: job_status , job_created_at , job_updated_at = airbyte . get_job_status ( session , airbyte_base_url , job_id ) # pending\u2503running\u2503incomplete\u2503failed\u2503succeeded\u2503cancelled if job_status == JOB_STATUS_SUCCEEDED : logger . info ( f \"Job { job_id } succeeded.\" ) elif job_status == JOB_STATUS_FAILED : logger . error ( f \"Job { job_id } failed.\" ) raise err . AirbyteSyncJobFailed ( f \"Job { job_id } failed.\" ) else : if status_updates : logger . info ( job_status ) # wait for next poll interval sleep ( poll_interval_s ) return { \"connection_id\" : connection_id , \"status\" : connection_status , \"job_status\" : job_status , \"job_created_at\" : job_created_at , \"job_updated_at\" : job_updated_at , } elif connection_status == CONNECTION_STATUS_INACTIVE : logger . error ( f \"Please enable the Connection { connection_id } in Airbyte Server.\" ) raise err . AirbyteServerNotHealthyException ( f \"Please enable the Connection { connection_id } in Airbyte Server.\" ) elif connection_status == CONNECTION_STATUS_DEPRECATED : logger . error ( f \"Connection { connection_id } is deprecated.\" ) raise err . AirbyteServerNotHealthyException ( f \"Connection { connection_id } is deprecated.\" )","title":"Connections"},{"location":"connections/#prefect_airbyte.connections","text":"Tasks for connecting to Airbyte and triggering connection syncs","title":"connections"},{"location":"connections/#prefect_airbyte.connections.trigger_sync","text":"Task run method for triggering an Airbyte Connection. It is assumed that the user will have previously configured a Source & Destination into a Connection. e.g. MySql -> CSV An invocation of run will attempt to start a sync job for the specified connection_id representing the Connection in Airbyte. run will poll Airbyte Server for the Connection status and will only complete when the sync has completed or when it receives an error status code from an API call. Parameters: Name Type Description Default str airbyte_server_host Hostname of Airbyte server where connection is configured. Will overwrite the value provided at init if provided. required str airbyte_server_port Port that the Airbyte server is listening on. Will overwrite the value provided at init if provided. required str airbyte_api_version Version of Airbyte API to use to trigger connection sync. Will overwrite the value provided at init if provided. required str connection_id if provided, will overwrite the value provided at init. required int poll_interval_s this task polls the Airbyte API for status, if provided this value will override the default polling time of 15 seconds. required bool status_updates whether to log status as the task polls jobs required Returns: Type Description dict connection_id (str) and succeeded_at (timestamp str) Examples: Flow that triggers an Airybte connection sync: from prefect import flow from prefect_airbyte.connections import trigger_sync @flow def example_trigger_sync_flow (): # Run other tasks and subflows here trigger_sync ( connection_id = \"your-connection-id-to-sync\" ) example_trigger_sync_flow () Source code in prefect_airbyte/connections.py @task async def trigger_sync ( airbyte_server_host : str = \"localhost\" , airbyte_server_port : int = \"8000\" , airbyte_api_version : str = \"v1\" , connection_id : str = None , poll_interval_s : int = 15 , status_updates : bool = False ) -> dict : \"\"\" Task run method for triggering an Airbyte Connection. *It is assumed that the user will have previously configured a Source & Destination into a Connection.* e.g. MySql -> CSV An invocation of `run` will attempt to start a sync job for the specified `connection_id` representing the Connection in Airbyte. `run` will poll Airbyte Server for the Connection status and will only complete when the sync has completed or when it receives an error status code from an API call. Args: str airbyte_server_host : Hostname of Airbyte server where connection is configured. Will overwrite the value provided at init if provided. str airbyte_server_port: Port that the Airbyte server is listening on. Will overwrite the value provided at init if provided. str airbyte_api_version: Version of Airbyte API to use to trigger connection sync. Will overwrite the value provided at init if provided. str connection_id: if provided, will overwrite the value provided at init. int poll_interval_s: this task polls the Airbyte API for status, if provided this value will override the default polling time of 15 seconds. bool status_updates: whether to log status as the task polls jobs Returns: dict: connection_id (str) and succeeded_at (timestamp str) Examples: Flow that triggers an Airybte connection sync: ```python from prefect import flow from prefect_airbyte.connections import trigger_sync @flow def example_trigger_sync_flow(): # Run other tasks and subflows here trigger_sync( connection_id=\"your-connection-id-to-sync\" ) example_trigger_sync_flow() ``` \"\"\" logger = get_logger () if not connection_id : raise ValueError ( \"Value for parameter `connection_id` *must* \\ be provided.\" ) try : uuid . UUID ( connection_id ) except ( TypeError , ValueError ): raise ValueError ( \"Parameter `connection_id` *must* be a valid UUID \\ i.e. 32 hex characters, including hyphens.\" ) # see https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com # /rapidoc-api-docs.html#overview airbyte_base_url = ( f \"http:// { airbyte_server_host } :\" f \" { airbyte_server_port } /api/ { airbyte_api_version } \" ) airbyte = AirbyteClient ( logger , airbyte_base_url ) session = airbyte . establish_session () logger . info ( f \"Getting Airbyte Connection { connection_id } , poll interval \" f \" { poll_interval_s } seconds, airbyte_base_url { airbyte_base_url } \" ) connection_status = airbyte . get_connection_status ( session , airbyte_base_url , connection_id ) if connection_status == CONNECTION_STATUS_ACTIVE : # Trigger manual sync on the Connection ... job_id , job_created_at = airbyte . trigger_manual_sync_connection ( session , airbyte_base_url , connection_id ) job_status = JOB_STATUS_PENDING while job_status not in [ JOB_STATUS_FAILED , JOB_STATUS_SUCCEEDED ]: job_status , job_created_at , job_updated_at = airbyte . get_job_status ( session , airbyte_base_url , job_id ) # pending\u2503running\u2503incomplete\u2503failed\u2503succeeded\u2503cancelled if job_status == JOB_STATUS_SUCCEEDED : logger . info ( f \"Job { job_id } succeeded.\" ) elif job_status == JOB_STATUS_FAILED : logger . error ( f \"Job { job_id } failed.\" ) raise err . AirbyteSyncJobFailed ( f \"Job { job_id } failed.\" ) else : if status_updates : logger . info ( job_status ) # wait for next poll interval sleep ( poll_interval_s ) return { \"connection_id\" : connection_id , \"status\" : connection_status , \"job_status\" : job_status , \"job_created_at\" : job_created_at , \"job_updated_at\" : job_updated_at , } elif connection_status == CONNECTION_STATUS_INACTIVE : logger . error ( f \"Please enable the Connection { connection_id } in Airbyte Server.\" ) raise err . AirbyteServerNotHealthyException ( f \"Please enable the Connection { connection_id } in Airbyte Server.\" ) elif connection_status == CONNECTION_STATUS_DEPRECATED : logger . error ( f \"Connection { connection_id } is deprecated.\" ) raise err . AirbyteServerNotHealthyException ( f \"Connection { connection_id } is deprecated.\" )","title":"trigger_sync()"}]}